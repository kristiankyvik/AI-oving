{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import random\n",
    "import difflib\n",
    "\n",
    "# loading training data\n",
    "train_df = pd.read_csv('./data/training.txt', sep=\"\\t\", header = None)\n",
    "train_df.columns  = [1, 2, 3, 4, 5, 6, 7, \"class\"]\n",
    "\n",
    "train_df = train_df.applymap(lambda x: True if x == 2 else False)\n",
    "        \n",
    "#loading testing data\n",
    "test_df = pd.read_csv('./data/test.txt', sep=\"\\t\", header = None)\n",
    "test_df.columns = [1, 2, 3, 4, 5, 6, 7, \"class\"]\n",
    "\n",
    "test_df = test_df.applymap(lambda x: True if x == 2 else False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#Method returning a decision tree implementing the importance function \n",
    "def decisionTreeLearning(examples, attributes, parent_examples):\n",
    "    attributes = attributes\n",
    "    if len(examples) == 0:\n",
    "        return pluralityValue(parent_examples)\n",
    "    elif allSameClass(examples):\n",
    "        return getClass(examples)\n",
    "    elif len(attributes) == 0:\n",
    "        return pluralityValue(examples)\n",
    "    else:\n",
    "        parent_examples = examples\n",
    "        next_att = importance(examples, attributes)\n",
    "        next_attributes = attributes\n",
    "        next_attributes.remove(next_att)\n",
    "        tree = [next_att, {True: decisionTreeLearning(examples[examples[next_att] == True], next_attributes, examples), False: decisionTreeLearning(examples[examples[next_att] == False], next_attributes, parent_examples)} ]\n",
    "        return tree\n",
    "\n",
    "#Method returning a dumb decision tree implementing without importance function \n",
    "def dumbDecisionTreeLearning(examples, attributes, parent_examples):\n",
    "    if len(examples) == 0:\n",
    "        return pluralityValue(parent_examples)\n",
    "    elif allSameClass(examples):\n",
    "        return getClass(examples)\n",
    "    elif len(attributes) == 0:\n",
    "        return pluralityValue(examples)\n",
    "    else:\n",
    "        parent_examples = examples\n",
    "        next_att = random.sample(set(attributes), 1)[0]\n",
    "        next_attributes = attributes\n",
    "        next_attributes.remove(next_att)\n",
    "        tree = [next_att, {True: dumbDecisionTreeLearning(examples[examples[next_att] == True], next_attributes, examples), False: dumbDecisionTreeLearning(examples[examples[next_att] == False], next_attributes, parent_examples)} ]\n",
    "        return tree\n",
    "    \n",
    "#Method returning plurality value\n",
    "def pluralityValue(examples):\n",
    "    true_count = (examples[\"class\"]).sum()\n",
    "    false_count = len(examples) - true_count\n",
    "    if true_count > false_count:\n",
    "        return True\n",
    "    elif true_count < false_count:\n",
    "        return False\n",
    "    else:\n",
    "        return random.sample(set([True, False]), 1)[0]\n",
    "\n",
    "#Method returning true if all remaining examples are of same class\n",
    "def allSameClass(examples):\n",
    "    return len(examples[\"class\"].value_counts()) == 1\n",
    "\n",
    "#Method returning the most common class    \n",
    "def getClass(examples):\n",
    "    return examples[\"class\"].iloc[0]\n",
    "\n",
    "#Method implementing the gain function\n",
    "def gain(examples, attribute):\n",
    "    pos = getPosCount(examples)\n",
    "    return B(pos/float(len(examples))) - remainder(examples, attribute)\n",
    "    \n",
    "#Method implementing the B function \n",
    "def B(q):\n",
    "    if q <= 0 or q == 1 :\n",
    "        return 0\n",
    "    result = - (q*np.log2(q) + (1 - q)*np.log2(1 - q))\n",
    "    return result\n",
    "\n",
    "#Method returning the remainder function\n",
    "def remainder(examples, attribute):\n",
    "    class_pos_count = getPosCount(examples)\n",
    "        \n",
    "    att_pos_split = examples[examples[attribute] == True]\n",
    "    att_neg_split =  examples[examples[attribute] == False]\n",
    "    \n",
    "    att_pos_class_pos_count = getPosCount(att_pos_split)\n",
    "    att_neg_class_pos_count = getPosCount(att_neg_split)\n",
    "        \n",
    "    remainder_att_pos = 0 if len(att_pos_split) == 0 else (len(att_pos_split)/float(len(examples))) * B(att_pos_class_pos_count/float(len(att_pos_split))) \n",
    "    remainder_att_neg = 0 if len(att_neg_split) == 0 else (len(att_neg_split)/float(len(examples))) * B(att_neg_class_pos_count/float(len(att_neg_split)))\n",
    "    return remainder_att_pos + remainder_att_neg  \n",
    " \n",
    "#Method that returns the number of instances classified as true\n",
    "def getPosCount(examples):\n",
    "    return (examples[\"class\"]).sum()\n",
    "\n",
    "#Method that implements the importance function\n",
    "def importance(examples, attributes):\n",
    "    gains_dicc = {att: gain(examples, att) for att in attributes}\n",
    "    max_gain = max(gains_dicc.values())\n",
    "    important_atts = filter(lambda att: gains_dicc[att] >= max_gain, attributes)\n",
    "    return random.sample(set(important_atts), 1)[0]\n",
    "\n",
    "#Helper method to classify an item/row acording to tree\n",
    "def classify(item, tree):\n",
    "    while True:\n",
    "        att = tree[0]\n",
    "        value = item[att]\n",
    "        dicc = tree[1]\n",
    "        tree = dicc[value]\n",
    "        if not isinstance(tree, list):\n",
    "            return tree\n",
    "\n",
    "#Helper method to classify a range of items\n",
    "def getResults(tree, df):\n",
    "    results = []\n",
    "    for index, row in df.iterrows():\n",
    "        results.append(classify(row, tree))\n",
    "    return results\n",
    "\n",
    "#Helper method asses performance, by comparing results obtained with tree with the actual classification\n",
    "def assessPerformance(results, actual_results):\n",
    "    sm=difflib.SequenceMatcher(None,results,actual_results)\n",
    "    return sm.ratio()\n",
    "\n",
    "   \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[7, {False: False, True: [2, {False: False, True: [5, {False: False, True: [6, {False: False, True: [3, {False: [4, {False: False, True: [1, {False: False, True: True}]}], True: False}]}]}]}]}]\n",
      "0.613928571429\n"
     ]
    }
   ],
   "source": [
    "#Lets try to build dumb decision tree (no information improvement)\n",
    "dumb_tree = dumbDecisionTreeLearning(train_df, [1, 2, 3, 4, 5, 6, 7], train_df)\n",
    "print dumb_tree\n",
    "\n",
    "#lets see how the dumb tree performs by averaging the performances of 100 runs\n",
    "dumbTreePerformances = []\n",
    "for i in range(100):\n",
    "    dumb_tree = dumbDecisionTreeLearning(train_df, [1, 2, 3, 4, 5, 6, 7 ], train_df)\n",
    "    results = getResults(dumb_tree, test_df)\n",
    "    actual_results = test_df[\"class\"].tolist()\n",
    "    dumbTreePerformances.append(assessPerformance(results, actual_results))\n",
    "\n",
    "print (sum(dumbTreePerformances)/len(dumbTreePerformances))\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1, {False: False, True: [5, {False: False, True: [6, {False: False, True: [7, {False: False, True: [4, {False: [2, {False: [3, {False: False, True: True}], True: True}], True: True}]}]}]}]}]\n",
      "0.693571428571\n"
     ]
    }
   ],
   "source": [
    "#Lets try to build a smart decision tree (with information improvement)\n",
    "tree = decisionTreeLearning(train_df, [1, 2, 3, 4, 5, 6, 7], train_df)\n",
    "print tree\n",
    "\n",
    "#lets see how the tree performs by averaging the performances of 100 runs\n",
    "treePerformances = []\n",
    "for i in range(100):\n",
    "    tree = decisionTreeLearning(train_df, [1, 2, 3, 4, 5, 6, 7], train_df)\n",
    "    results = getResults(tree, test_df)\n",
    "    actual_results = test_df[\"class\"].tolist()\n",
    "    treePerformances.append(assessPerformance(results, actual_results))\n",
    "\n",
    "print (sum(treePerformances)/len(treePerformances))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
